"""
===============================================================================
File: ukf_aliter.py
Author: Anubhab Ghosh (Feb 2023) | Annotated by ChatGPT (2025)
Adopted from: https://github.com/KalmanNet/KalmanNet_TSP
-------------------------------------------------------------------------------
ğŸ¯ èƒŒæ™¯ (Background)
- ä¸»é¢˜ï¼šéçº¿æ€§çŠ¶æ€ä¼°è®¡ï¼ˆUnscented Kalman Filter, UKFï¼‰åœ¨ Lorenz ç­‰éçº¿æ€§ç³»ç»Ÿä¸Šçš„å®ç°ã€‚
- æ ¸å¿ƒï¼šé€šè¿‡æ— è¿¹å˜æ¢ï¼ˆUnscented Transform, UTï¼‰ä¼ æ’­å‡å€¼ä¸åæ–¹å·®ï¼Œé¿å…ä¸€é˜¶çº¿æ€§åŒ–è¯¯å·®ã€‚

ğŸ“¥ğŸ“¤ è¾“å…¥è¾“å‡ºæ¦‚è§ˆ (I/O Overview)
- System functions:
  - f: éçº¿æ€§çŠ¶æ€è½¬ç§»å‡½æ•°ï¼Œæ¥å£ fx(x, dt) -> x_next
  - h: éçº¿æ€§è§‚æµ‹å‡½æ•°ï¼Œæ¥å£ hx(x) -> z_hat
- Data tensors:
  - X: çœŸå®çŠ¶æ€è½¨è¿¹ï¼Œå½¢çŠ¶ [N, T_x, n_states]
  - Y: è§‚æµ‹åºåˆ—ï¼Œå½¢çŠ¶ [N, T_y, n_obs]
  - è¿”å›ä¼°è®¡ï¼š
      traj_estimated: UKF çš„çŠ¶æ€åéªŒä¼°è®¡ï¼Œå½¢çŠ¶ [N, T_x, n_states]
      Pk_estimated: UKF çš„åéªŒåæ–¹å·®ï¼Œå½¢çŠ¶ [N, T_x, n_states, n_states]
      MSE_UKF_linear_arr.mean(): å¹³å‡ MSEï¼ˆçº¿æ€§å°ºåº¦ï¼‰
      mse_ukf_dB_avg: å¹³å‡ MSEï¼ˆdB å°ºåº¦ï¼‰

ğŸ‘¥ ç›®æ ‡è¯»è€… (Intended Audience)
- æ—¢é¢å‘åˆå­¦è€…ï¼ˆå¸Œæœ›å¿«é€ŸæŒæ¡ UKF çš„æ•°æ®ç»´åº¦ä¸è°ƒç”¨æ–¹å¼ï¼‰ï¼Œä¹Ÿé¢å‘ç ”ç©¶è€…/å·¥ç¨‹å¸ˆï¼ˆå…³æ³¨æ•°å­¦å»ºæ¨¡ä¸å®ç°ç»†èŠ‚ï¼‰ã€‚
- æ³¨é‡Šé‡‡ç”¨ä¸­è‹±æ··æ’ï¼šä¸­æ–‡è§£é‡Šå·¥ç¨‹åŠ¨æœºï¼›è‹±æ–‡ä¿æŒå˜é‡/å‡½æ•°åä¸€è‡´ä»¥ä¾¿æ£€ç´¢ã€‚
===============================================================================
"""

#####################################################
# Creator: Anubhab Ghosh
# Feb 2023
# Adopted from: https://github.com/KalmanNet/KalmanNet_TSP
#####################################################
try:
    from filterpy.kalman import UnscentedKalmanFilter, MerweScaledSigmaPoints, JulierSigmaPoints
except Exception as _filterpy_exc:  # pragma: no cover - fallback for environments without filterpy deps
    UnscentedKalmanFilter = None
    MerweScaledSigmaPoints = None
    JulierSigmaPoints = None
    _FILTERPY_IMPORT_ERROR = _filterpy_exc
else:  # pragma: no cover - import succeeded
    _FILTERPY_IMPORT_ERROR = None

try:
    from scipy.linalg import expm
except Exception:  # pragma: no cover - allow running without SciPy
    expm = None
import torch
from torch import nn
from timeit import default_timer as timer
import numpy as np
import math


def dB_to_lin(x_dB: float) -> float:
    """Convert decibels to linear scale."""

    return 10.0 ** (x_dB / 10.0)


def lin_to_dB(x_lin: float, eps: float = 1e-12) -> float:
    """Convert linear value to dB with numerical floor."""

    return 10.0 * np.log10(max(x_lin, eps))


def mse_loss(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:
    """Mean squared error between two tensors."""

    return torch.mean((a - b) ** 2)


def lorenz_rhs(x: np.ndarray, sigma: float = 10.0, rho: float = 28.0, beta: float = 8.0 / 3.0) -> np.ndarray:
    """Lorenz-63 continuous-time dynamics."""

    x1, x2, x3 = x
    return np.array([
        sigma * (x2 - x1),
        x1 * (rho - x3) - x2,
        x1 * x2 - beta * x3,
    ], dtype=float)


def lorenz_rk4(x: np.ndarray, dt: float) -> np.ndarray:
    """RK4 step for Lorenz dynamics."""

    k1 = lorenz_rhs(x)
    k2 = lorenz_rhs(x + 0.5 * dt * k1)
    k3 = lorenz_rhs(x + 0.5 * dt * k2)
    k4 = lorenz_rhs(x + dt * k3)
    return x + (dt / 6.0) * (k1 + 2.0 * k2 + 2.0 * k3 + k4)


def _merwe_sigma_points_np(x: np.ndarray, P: np.ndarray, alpha: float, beta: float, kappa: float,
                           jitter: float = 1e-9) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    """Return sigma points and weights for the given mean/covariance."""

    n = x.shape[0]
    lambda_ = alpha ** 2 * (n + kappa) - n
    scaling = n + lambda_
    if scaling <= 0:
        raise ValueError("Sigma point scaling factor must be positive. Check alpha/kappa settings.")

    P_safe = 0.5 * (P + P.T) + jitter * np.eye(n)
    try:
        sqrt_matrix = np.linalg.cholesky(scaling * P_safe)
    except np.linalg.LinAlgError:
        sqrt_matrix = np.linalg.cholesky(scaling * (P_safe + jitter * np.eye(n)))

    sigma = np.zeros((2 * n + 1, n), dtype=float)
    sigma[0] = x
    for i in range(n):
        col = sqrt_matrix[:, i]
        sigma[i + 1] = x + col
        sigma[n + i + 1] = x - col

    Wm = np.full(2 * n + 1, 1.0 / (2.0 * scaling), dtype=float)
    Wc = np.full(2 * n + 1, 1.0 / (2.0 * scaling), dtype=float)
    Wm[0] = lambda_ / scaling
    Wc[0] = lambda_ / scaling + (1.0 - alpha ** 2 + beta)

    return sigma, Wm, Wc


def _covariance_from_sigma(sigma: np.ndarray, mean: np.ndarray, Wc: np.ndarray,
                           jitter: float = 1e-9) -> np.ndarray:
    """Compute covariance from sigma points and weights."""

    diff = sigma - mean
    cov = diff.T @ (Wc[:, None] * diff)
    cov = 0.5 * (cov + cov.T)
    cov += jitter * np.eye(mean.size)
    return cov


def A_fn_exact(z, dt):
    """
    Compute exact one-step flow of the continuous-time Lorenz system using matrix exponential.
    ä½¿ç”¨çŸ©é˜µæŒ‡æ•°å¯¹è¿ç»­æ—¶é—´ Lorenz ç³»ç»Ÿè¿›è¡Œä¸€é˜¶ç²¾ç¡®ç¦»æ•£åŒ–ï¼Œå¹¶ä½œç”¨äºçŠ¶æ€å‘é‡ã€‚

    Args:
        z (np.ndarray): å½“å‰çŠ¶æ€å‘é‡ current state, shape [3,], order [x, y, z].
        dt (float): é‡‡æ ·å‘¨æœŸ sampling time step.

    Returns:
        np.ndarray: ä¸‹ä¸€æ—¶åˆ»çŠ¶æ€çš„çº¿æ€§è¿‘ä¼¼ç»“æœï¼ˆé€šè¿‡å±€éƒ¨çº¿æ€§åŒ–çŸ©é˜µæŒ‡æ•°å¾—åˆ°ï¼‰,
                    shape [3,].

    Tensor Dimensions:
        z âˆˆ R^[3], dt âˆˆ R, return âˆˆ R^[3]

    Math Notes:
        Continuous-time linearization around state z:
            A(z) =
                [[-10,   10,      0],
                 [ 28,   -1,   -z_x],
                 [  0,   z_x,  -8/3]]
        Then state propagation (local linear model):
            x_{k+1} â‰ˆ expm(A(z_k) * dt) @ z_k
        è¯¥å‡½æ•°å°† A(z) çš„çŸ©é˜µæŒ‡æ•°ç›´æ¥ä¹˜ä»¥å½“å‰çŠ¶æ€ï¼Œå®ç°ä¸€é˜¶ç²¾ç¡®ç¦»æ•£åŒ–çš„è¿‘ä¼¼ã€‚
    """
    # ==========================================================================
    # STEP 01: è®¡ç®—çŠ¶æ€ç›¸å…³çš„é›…å¯æ¯”çŸ©é˜µ A(z)
    # --------------------------------------------------------------------------
    # Lorenz ç³»ç»Ÿçš„çº¿æ€§åŒ–çŸ©é˜µ A ä¾èµ–äºå½“å‰ x åˆ†é‡ (z[0]); è¿™é‡Œä½¿ç”¨ç»å…¸å‚æ•°ã€‚
    # ==========================================================================
    if expm is None:
        return lorenz_rk4(z, dt)

    return expm(np.array([
                    [-10, 10, 0],
                    [28, -1, -z[0]],
                    [0, z[0], -8.0/3]
                ]) * dt) @ z


'''
def f_lorenz_danse(x, dt):
    # NOTE: This alternative formulation uses a Taylor expansion to build F.
    # è¯´æ˜ï¼šè¯¥æ®µä¸ºæ›¿ä»£æ€§å®ç°ï¼ˆä¿ç•™ä¸ºæ³¨é‡Šï¼‰ï¼Œé€šè¿‡æ³°å‹’å±•å¼€è¿‘ä¼¼çŠ¶æ€è½¬ç§»çŸ©é˜µ Fã€‚
    # ä¸å»ºè®®åœ¨ç”Ÿäº§ä¸­ç›´æ¥å¯ç”¨ï¼Œå› å­˜åœ¨ç¡¬ç¼–ç ä¾èµ–å’Œæ½œåœ¨è®¾å¤‡/æ¢¯åº¦é—®é¢˜ã€‚

    x = torch.from_numpy(x).type(torch.FloatTensor)
    B = torch.Tensor([[[0,  0, 0],[0, 0, -1],[0,  1, 0]], torch.zeros(3,3), torch.zeros(3,3)]).type(torch.FloatTensor)
    C = torch.Tensor([[-10, 10,    0],
                    [ 28, -1,    0],
                    [  0,  0, -8/3]]).type(torch.FloatTensor)
    #A = torch.add(torch.einsum('nhw,wa->nh', B, x).T,C)
    A = torch.einsum('kn,nij->ij',x.reshape((1,-1)),B)
    #A = torch.reshape(torch.matmul(B, x),(3,3)).T # For KalmanNet
    A += C
    #delta = delta_t # Hardcoded for now
    # Taylor Expansion for F
    F = torch.eye(3)
    J = J_test # Hardcoded for now
    for j in range(1,J+1):
        F_add = (torch.matrix_power(A*delta_t, j)/math.factorial(j))
        F = torch.add(F, F_add)
    return torch.matmul(F, x).numpy()
'''


class UKF_Aliter(nn.Module):
    """This class implements an Unscented Kalman Filter (UKF) using FilterPy under a PyTorch wrapper.
    è¯¥ç±»å°è£… FilterPy çš„ UKFï¼Œåœ¨ PyTorch è®¾å¤‡ä¸Šç®¡ç†å¼ é‡ä¸æ‰¹å¤„ç†æ¥å£ï¼ˆä¸æ”¹å˜ FilterPy å†…éƒ¨å®ç°ï¼‰ã€‚

    Args:
        n_states (int): çŠ¶æ€ç»´åº¦ number of states n_x.
        n_obs (int): è§‚æµ‹ç»´åº¦ number of observations n_z.
        f (callable): çŠ¶æ€è½¬ç§»å‡½æ•° fx(x, dt) -> x_nextï¼Œéçº¿æ€§ã€‚
        h (callable): è§‚æµ‹å‡½æ•° hx(x) -> z_hatï¼Œéçº¿æ€§ã€‚
        Q (np.ndarray | None): è¿‡ç¨‹å™ªå£°åæ–¹å·® process noise cov, shape [n_states, n_states].
        R (np.ndarray | None): è§‚æµ‹å™ªå£°åæ–¹å·® measurement noise cov, shape [n_obs, n_obs].
        kappa (float): UT è¶…å‚æ•°ï¼Œå†³å®š sigma ç‚¹åˆ†å¸ƒçš„ç¦»æ•£åº¦ã€‚
        alpha (float): UT è¶…å‚æ•°ï¼Œé€šå¸¸å– 1e-3~0.5ï¼Œå°åˆ™ sigma ç‚¹æ›´é è¿‘å‡å€¼ã€‚
        beta (float): UT è¶…å‚æ•°ï¼Œé’ˆå¯¹é«˜æ–¯åˆ†å¸ƒå¸¸å– 2ã€‚
        n_sigma (int | None): æœªä½¿ç”¨çš„å ä½å‚æ•°ï¼ˆä¿ç•™å…¼å®¹ï¼‰ã€‚
        delta_t (float): é‡‡æ ·å‘¨æœŸ sampling time step ç”¨äº FilterPy UKFã€‚
        inverse_r2_dB (float | None): è‹¥æä¾›ï¼Œä¸ nu_dB å…±åŒå†³å®š Q å’Œ Rï¼ˆä»¥ dB å°ºåº¦ç»™å‡ºï¼‰ã€‚
        nu_dB (float | None): å™ªå£°åŠŸç‡å·®ï¼ˆdBï¼‰ï¼Œç”¨äºä» inverse_r2_dB æ¨å‡º q2ã€‚
        device (str): PyTorch è®¾å¤‡, e.g., "cpu" æˆ– "cuda".
        init_cond (torch.Tensor | None): åˆå§‹æ¡ä»¶ï¼ˆå½“å‰æœªä½¿ç”¨ï¼›ä¿ç•™æ¥å£ï¼‰ã€‚

    Attributes:
        device (str): å½“å‰è®¾å¤‡ã€‚
        n_states (int), n_obs (int): ç»´åº¦ä¿¡æ¯ã€‚
        f_k, h_k (callable): éçº¿æ€§ç³»ç»Ÿå‡½æ•°ã€‚
        Q_k, R_k (torch.FloatTensor): è¿‡ç¨‹/è§‚æµ‹å™ªå£°åæ–¹å·®ï¼ˆé©»ç•™åœ¨ deviceï¼‰ã€‚
        sigma_points (MerweScaledSigmaPoints): æ— è¿¹å˜æ¢ sigma ç‚¹ç”Ÿæˆå™¨ã€‚
        ukf (filterpy.kalman.UnscentedKalmanFilter): FilterPy UKF å®ä¾‹ã€‚

    Tensor Dimensions:
        Q_k âˆˆ R^[n_states, n_states], R_k âˆˆ R^[n_obs, n_obs]
        ukf.x âˆˆ R^[n_states], ukf.P âˆˆ R^[n_states, n_states]

    Math Notes:
        UT é€šè¿‡é€‰å– 2n+1 ä¸ª sigma ç‚¹ {chi_i} åŠæƒé‡ {W_i} æ¥ä¼ æ’­éçº¿æ€§ï¼š
            x_pred   = sum_i W_i^m * f(chi_i, dt)
            P_pred   = sum_i W_i^c * (f(chi_i) - x_pred)(...)^T + Q
            z_pred   = sum_i W_i^m * h(chi_i)
            P_zz     = sum_i W_i^c * (h(chi_i) - z_pred)(...)^T + R
            P_xz     = sum_i W_i^c * (chi_i - x_pred)(h(chi_i) - z_pred)^T
            K        = P_xz @ inv(P_zz)
            x_post   = x_pred + K @ (z - z_pred)
            P_post   = P_pred - K @ P_zz @ K^T
    """
    def __init__(self, n_states, n_obs, f=None, h=None, Q=None, R=None, kappa=-1,
                alpha=0.1, beta=2, n_sigma=None, delta_t=1.0, inverse_r2_dB=None,
                nu_dB=None, device='cpu', init_cond=None):
        super(UKF_Aliter, self).__init__()

        if UnscentedKalmanFilter is None or MerweScaledSigmaPoints is None:
            raise RuntimeError(
                "FilterPy æœªæˆåŠŸå¯¼å…¥ï¼Œæ— æ³•å®ä¾‹åŒ– UKF_Aliter. åŸå› : "
                f"{_FILTERPY_IMPORT_ERROR!r}"
            )

        # ==========================================================================
        # STEP 01: è®¾å¤‡ä¸ç³»ç»Ÿç»´åº¦åˆå§‹åŒ– (Device & dimensions)
        # ==========================================================================
        self.device = device
        self.n_states = n_states
        self.n_obs = n_obs
        self.f_k = f
        self.h_k = h

        # ==========================================================================
        # STEP 02: å™ªå£°åæ–¹å·®æ¥æº (Noise covariance setup)
        # --------------------------------------------------------------------------
        # è‹¥æä¾› inverse_r2_dB ä¸ nu_dB ä¸” Q/R æœªæ˜¾å¼ç»™å‡ºï¼Œåˆ™ä½¿ç”¨ dB è§„åˆ™æ„é€ ã€‚
        # è®¾è®¡åŸå› ï¼šä¾¿äºä»…é€šè¿‡ä¿¡å™ªå‚æ•°å¿«é€Ÿè®¾å®šæ»¤æ³¢å™¨è¶…å‚ã€‚
        # r2 = 1 / SNR_linear; q2 = 10^((nu_dB - inverse_r2_dB)/10)
        # ==========================================================================
        if (not inverse_r2_dB is None) and (not nu_dB is None) and (Q is None) and (R is None):
            r2 = 1.0 / dB_to_lin(inverse_r2_dB)
            q2 = dB_to_lin(nu_dB - inverse_r2_dB)
            Q = q2 * np.eye(self.n_states)
            R = r2 * np.eye(self.n_obs)

        if Q is None or R is None:
            raise ValueError("Q/R æœªæä¾›ï¼Œä¸”æ— æ³•ä» dB å‚æ•°æ¨å¯¼ã€‚")

        # å°† numpy è½¬ä¸ºé©»ç•™åœ¨ device çš„ torch å¼ é‡
        self.Q_k = self.push_to_device(Q)  # è¿‡ç¨‹å™ªå£°åæ–¹å·® Q
        self.R_k = self.push_to_device(R)  # è§‚æµ‹å™ªå£°åæ–¹å·® R

        # ==========================================================================
        # STEP 03: æ— è¿¹å˜æ¢è¶…å‚æ•°ä¸ sigma ç‚¹ (UT hyperparams & sigma points)
        # ==========================================================================
        self.kappa = kappa
        self.alpha = alpha
        self.beta = beta
        self.get_sigma_points()  # è®¾ç½® self.sigma_points

        # self.init_cond = init_cond  # ä¿ç•™æ¥å£ï¼ˆå½“å‰æœªå¯ç”¨ï¼‰

        # ==========================================================================
        # STEP 04: æ„å»º FilterPy çš„ UKF å®ä¾‹ (Instantiate FilterPy UKF)
        # ==========================================================================
        self.delta_t = delta_t
        self.ukf = UnscentedKalmanFilter(dim_x=self.n_states, dim_z=self.n_obs, dt=self.delta_t,
                                        fx=self.f_k, hx=self.h_k, points=self.sigma_points)
        # å°†å™ªå£°ä¸åˆå€¼åŒæ­¥åˆ° FilterPy UKF (FilterPy æœŸæœ› numpy)
        self.ukf.R = self.R_k.numpy()
        self.ukf.Q = self.Q_k.numpy()
        self.ukf.x = torch.ones((self.n_states,)).numpy()
        self.ukf.P = (torch.eye(self.n_states) * 1e-5).numpy()
        return None

    def initialize(self):
        """
        Reset internal UKF posterior mean and covariance.
        é‡ç½® UKF çš„å†…éƒ¨åéªŒå‡å€¼ä¸åæ–¹å·®ï¼ˆæ¯ä¸ªæ ·æœ¬åºåˆ—å¼€å§‹æ—¶è°ƒç”¨ï¼‰ã€‚

        Args:
            None

        Returns:
            None

        Tensor Dimensions:
            ukf.x âˆˆ R^[n_states], ukf.P âˆˆ R^[n_states, n_states]

        Math Notes:
            x_post_0 = 1 (per component)
            P_post_0 = 1e-5 * I
            å°æ–¹å·®åˆå€¼æ„å‘³ç€å¯¹åˆå§‹çŠ¶æ€æœ‰å¼ºå…ˆéªŒçº¦æŸï¼›è‹¥å…ˆéªŒä¸å‡†ï¼Œå¯èƒ½æ”¶æ•›è¾ƒæ…¢ã€‚
        """
        # ==========================================================================
        # STEP 01: é‡ç½®åéªŒ
        # ==========================================================================
        self.ukf.x = torch.ones((self.n_states,)).numpy()
        self.ukf.P = (torch.eye(self.n_states) * 1e-5).numpy()

    def push_to_device(self, x):
        """
        Convert a numpy array to torch.FloatTensor on the configured device.
        å°† numpy æ•°ç»„è½¬æ¢ä¸ºä½äºæŒ‡å®š device çš„ FloatTensorã€‚

        Args:
            x (np.ndarray): è¾“å…¥çŸ©é˜µ/å‘é‡ input array.

        Returns:
            torch.FloatTensor: ä½äº self.device çš„å¼ é‡ã€‚

        Tensor Dimensions:
            ä¿æŒä¸è¾“å…¥ç›¸åŒçš„å½¢çŠ¶ï¼›ä»…æ”¹å˜ç±»å‹ä¸è®¾å¤‡ã€‚

        Math Notes:
            æ— æ•°å­¦å˜æ¢ï¼Œä»…æ•°æ®ç±»å‹ä¸å†…å­˜ä½ç½®è½¬æ¢ã€‚
        """
        # ==========================================================================
        # STEP 01: ç±»å‹ä¸è®¾å¤‡è¿ç§»
        # ==========================================================================
        return torch.from_numpy(x).type(torch.FloatTensor).to(self.device)

    def get_sigma_points(self):
        """
        Construct sigma point generator (MerweScaledSigmaPoints).
        æ„é€  Merwe ç¼©æ”¾ sigma ç‚¹ç”Ÿæˆå™¨ã€‚

        Args:
            None

        Returns:
            None

        Math Notes:
            MerweScaledSigmaPoints é€šè¿‡ (alpha, beta, kappa) æ§åˆ¶ç‚¹åˆ†å¸ƒä¸æƒé‡ã€‚
            å¯¹é«˜æ–¯åˆ†å¸ƒï¼Œbeta=2 é€šå¸¸æœ€ä¼˜ï¼›alpha æ§åˆ¶åˆ†å¸ƒåŠå¾„ï¼›kappa å½±å“ç¦»æ•£åº¦ã€‚
        """
        # ==========================================================================
        # STEP 01: åˆå§‹åŒ– sigma ç‚¹ç­–ç•¥
        # ==========================================================================
        self.sigma_points = MerweScaledSigmaPoints(self.n_states, alpha=self.alpha, beta=self.beta, kappa=self.kappa)

    def run_mb_filter(self, X, Y, U=None):
        """
        Run UKF over a mini-batch of sequences and compute MSE.
        åœ¨å°æ‰¹é‡åºåˆ—ä¸Šè¿è¡Œ UKFï¼Œå¹¶è¿”å›è½¨è¿¹ä¼°è®¡åŠ MSE ç»Ÿè®¡ã€‚

        Args:
            X (torch.Tensor): çœŸå®çŠ¶æ€è½¨è¿¹ ground-truth states,
                shape [N, T_x, n_states] æˆ– [T_x, n_states]ï¼ˆå°†è‡ªåŠ¨å‡ç»´ä¸º N=1ï¼‰ã€‚
            Y (torch.Tensor): è§‚æµ‹åºåˆ— measurements,
                shape [N, T_y, n_obs] æˆ– [T_y, n_obs]ï¼ˆå°†è‡ªåŠ¨å‡ç»´ä¸º N=1ï¼‰ã€‚
            U (torch.Tensor | None): æ§åˆ¶è¾“å…¥ control inputsï¼ˆæœªä½¿ç”¨ï¼Œä¿ç•™æ¥å£ï¼‰ã€‚

        Returns:
            tuple:
                traj_estimated (torch.FloatTensor): åéªŒçŠ¶æ€ä¼°è®¡, shape [N, T_x, n_states].
                Pk_estimated (torch.FloatTensor): åéªŒåæ–¹å·®ä¼°è®¡, shape [N, T_x, n_states, n_states].
                MSE_UKF_linear_arr.mean() (torch.FloatTensor): å¹³å‡ MSEï¼ˆçº¿æ€§å°ºåº¦æ ‡é‡ï¼‰ã€‚
                mse_ukf_dB_avg (torch.FloatTensor): å¹³å‡ MSEï¼ˆdB å°ºåº¦æ ‡é‡ï¼‰ã€‚

        Tensor Dimensions:
            N: batch size; T_x: çŠ¶æ€åºåˆ—é•¿åº¦; T_y: è§‚æµ‹åºåˆ—é•¿åº¦
            n_states: çŠ¶æ€ç»´åº¦ï¼›n_obs: è§‚æµ‹ç»´åº¦

        Math Notes:
            å¤„ç†æµç¨‹ï¼š
                for each sequence i:
                    initialize posterior (x_post_0, P_post_0)
                    for k in 0..T_y-1:
                        predict via UT: (x_pred, P_pred)
                        update with y[k]: (x_post, P_post)
                    compute MSE_i = mse(X_i[1:], traj_i[1:])
            è¿™é‡Œå°†ç¬¬ä¸€æ­¥ä¼°è®¡ä¸è§‚æµ‹å¯¹é½ï¼Œä» k=0 å¼€å§‹ï¼Œæœ€åè¯„ä¼°ä½¿ç”¨ 1: å¯¹é½ç´¢å¼•ã€‚
        """
        # ==========================================================================
        # STEP 00: ç»´åº¦è§£æä¸å¼ é‡å‡†å¤‡ (Shape parsing & allocation)
        # ==========================================================================
        _, Ty, dy = Y.shape
        _, Tx, dx = X.shape

        if len(Y.shape) == 3:
            N, T, d = Y.shape
        elif len(Y.shape) == 2:
            T, d = Y.shape
            N = 1
            Y = Y.reshape((N, Ty, d))

        # ä¼°è®¡è½¨è¿¹ä¸åæ–¹å·®ç¼“å­˜ï¼ˆé©»ç•™ deviceï¼‰
        traj_estimated = torch.zeros((N, Tx, self.n_states), device=self.device).type(torch.FloatTensor)
        Pk_estimated = torch.zeros((N, Tx, self.n_states, self.n_states), device=self.device).type(torch.FloatTensor)

        # æ‰¹å†…æ¯ä¸ªåºåˆ—çš„ MSEï¼ˆçº¿æ€§å°ºåº¦ï¼‰
        MSE_UKF_linear_arr = torch.zeros((N,)).type(torch.FloatTensor)
        # points = JulierSigmaPoints(n=SysModel.m)  # å¤‡ç”¨ sigma ç‚¹æ–¹æ¡ˆï¼ˆæœªå¯ç”¨ï¼‰

        # ==========================================================================
        # STEP 01: æ‰¹å¤„ç†ä¸»å¾ªç¯ (Main batch loop)
        # ==========================================================================
        start = timer()
        for i in range(0, N):
            # æ¯ä¸ªæ ·æœ¬åºåˆ—é‡ç½®æ»¤æ³¢å™¨åˆå€¼
            self.initialize()
            # if self.init_cond is not None:
            #     self.ukf.x = torch.unsqueeze(self.init_cond[i, :], 1).numpy()

            # ----------------------------------------------------------------------
            # STEP 01a: æ—¶é—´æ­¥è¿­ä»£ (Time-step loop)
            # ----------------------------------------------------------------------
            for k in range(0, Ty):
                # å…ˆéªŒé¢„æµ‹ï¼šUT ä¼ æ’­å‡å€¼ä¸åæ–¹å·®
                self.ukf.predict()
                # è§‚æµ‹æ›´æ–°ï¼šèåˆå½“å‰è§‚æµ‹ Y[i, k, :]
                self.ukf.update(Y[i, k, :].numpy())

                # è®°å½•åéªŒå‡å€¼ä¸åæ–¹å·®ï¼ˆk+1 å¯¹é½åˆ° X çš„ç´¢å¼•æ–¹æ¡ˆï¼‰
                traj_estimated[i, k+1, :] = torch.from_numpy(self.ukf.x)
                Pk_estimated[i, k+1, :, :] = torch.from_numpy(self.ukf.P)

            # ä»¥å¯¹é½åçš„æ—¶åºçª—å£è¯„ä¼° MSE
            # MSE_UKF_linear_arr[i] = mse_loss(traj_estimated[i], X[i]).item()
            MSE_UKF_linear_arr[i] = mse_loss(X[i, 1:, :], traj_estimated[i, 1:, :]).mean().item()
            # print("ukf, sample: {}, mse_loss: {}".format(i+1, MSE_UKF_linear_arr[i]))

        end = timer()
        t = end - start  # è¿è¡Œæ—¶é•¿ï¼Œå¯ç”¨äºæ—¥å¿—
        # print("Inference Time:", t)

        # ==========================================================================
        # STEP 02: ç»Ÿè®¡ä¸æ—¥å¿— (Statistics & logging)
        # ==========================================================================
        # MSE_UKF_linear_avg = torch.mean(MSE_UKF_linear_arr)
        # MSE_UKF_dB_avg = 10 * torch.log10(MSE_UKF_linear_avg)
        # MSE_UKF_linear_std = torch.std(MSE_UKF_linear_arr, unbiased=True)
        # MSE_UKF_dB_std = 10 * torch.log10(MSE_UKF_linear_std.abs())

        mse_ukf_dB_avg = torch.mean(10 * torch.log10(MSE_UKF_linear_arr), dim=0)
        print("UKF - MSE LOSS:", mse_ukf_dB_avg, "[dB]")
        print("UKF - MSE STD:", torch.std(10 * torch.log10(MSE_UKF_linear_arr), dim=0), "[dB]")

        # ==========================================================================
        # STEP 03: è¿”å›ç»“æœ (Return results)
        # ==========================================================================
        return traj_estimated, Pk_estimated, MSE_UKF_linear_arr.mean(), mse_ukf_dB_avg


def _load_lorenz_dataset(dataset_path):
    """Load pickled Lorenz trajectories with numpy._core compatibility."""

    import pickle

    class _CompatUnpickler(pickle.Unpickler):
        def find_class(self, module, name):
            if module.startswith("numpy._core"):
                module = module.replace("numpy._core", "numpy.core")
            return super().find_class(module, name)

    with open(dataset_path, "rb") as handle:
        return _CompatUnpickler(handle).load()


if __name__ == "__main__":
    import argparse
    from pathlib import Path

    parser = argparse.ArgumentParser(description="UKF demo on stored Lorenz dataset.")
    parser.add_argument(
        "--dataset",
        #src/data/trajectories/trajectories_m_3_n_3_LorenzSSM_data_T_1000_N_500_r2_20.0dB_nu_-10.0dB.pkl
        default="src/data/trajectories/trajectories_m_3_n_3_LorenzSSM_data_T_1000_N_500_r2_20.0dB_nu_-10.0dB.pkl",
        help="Path to Lorenz trajectory pickle.",
    )
    parser.add_argument("--index", type=int, default=0, help="Sample index to visualise.")
    args = parser.parse_args()

    dataset_path = Path(args.dataset)
    if not dataset_path.exists():
        raise FileNotFoundError(f"Dataset not found: {dataset_path}")

    payload = _load_lorenz_dataset(dataset_path)
    num_samples = payload["num_samples"]
    if not (0 <= args.index < num_samples):
        raise IndexError(f"index {args.index} out of range (0 â‰¤ idx < {num_samples}).")

    sample_X, sample_Y = payload["data"][args.index]
    sample_X = np.asarray(sample_X, dtype=float)
    sample_Y = np.asarray(sample_Y, dtype=float)

    dt = 0.02
    alpha, beta, kappa = 0.1, 2.0, -1.0
    r2 = 1.0 / dB_to_lin(0.0)
    q2 = dB_to_lin(-10.0 - 0.0)
    Q = q2 * np.eye(sample_X.shape[1])
    R = r2 * np.eye(sample_Y.shape[1])
    jitter = 1e-6

    x_post = sample_Y[0].astype(float)
    P_post = np.eye(sample_X.shape[1]) * 5.0

    estimates = np.zeros_like(sample_Y)
    covariances = np.zeros((sample_Y.shape[0], sample_X.shape[1], sample_X.shape[1]))

    for t in range(sample_Y.shape[0]):
        sigma, Wm, Wc = _merwe_sigma_points_np(x_post, P_post, alpha, beta, kappa, jitter)
        propagated = np.array([A_fn_exact(sp, dt) for sp in sigma])
        x_pred = np.sum(Wm[:, None] * propagated, axis=0)
        P_pred = _covariance_from_sigma(propagated, x_pred, Wc, jitter) + Q
        sigma_pred, Wm_pred, Wc_pred = _merwe_sigma_points_np(x_pred, P_pred, alpha, beta, kappa, jitter)
        Z_sigma = sigma_pred  # h(x)=x
        z_pred = np.sum(Wm_pred[:, None] * Z_sigma, axis=0)
        S = _covariance_from_sigma(Z_sigma, z_pred, Wc_pred, jitter) + R
        Pxz = (sigma_pred - x_pred).T @ (Wc_pred[:, None] * (Z_sigma - z_pred))
        K = Pxz @ np.linalg.inv(S)
        innov = sample_Y[t] - z_pred
        x_post = x_pred + K @ innov
        P_post = P_pred - K @ S @ K.T
        P_post = 0.5 * (P_post + P_post.T) + jitter * np.eye(P_post.shape[0])

        estimates[t] = x_post
        covariances[t] = P_post

    x_hat_full = np.zeros_like(sample_X)
    x_hat_full[0] = sample_X[0]
    x_hat_full[1:] = estimates
    x_hat_np = x_hat_full[1:]

    mse_per_step = np.mean((x_hat_np - sample_X[1:, :]) ** 2, axis=1)
    mse_lin = float(np.mean(mse_per_step))
    mse_db = lin_to_dB(mse_lin)
    time_axis = np.arange(sample_Y.shape[0])

    import matplotlib

    matplotlib.use("Agg")

    import matplotlib.cbook as _mpl_cbook

    if not hasattr(_mpl_cbook, "_is_pandas_dataframe"):
        def _is_pandas_dataframe(_obj):
            return False

        _mpl_cbook._is_pandas_dataframe = _is_pandas_dataframe

    if not hasattr(_mpl_cbook, "_Stack") and hasattr(_mpl_cbook, "Stack"):
        _mpl_cbook._Stack = _mpl_cbook.Stack

    if not hasattr(_mpl_cbook, "_ExceptionInfo"):
        from collections import namedtuple

        _mpl_cbook._ExceptionInfo = namedtuple("_ExceptionInfo", "exc_class exc traceback")

    if not hasattr(_mpl_cbook, "_broadcast_with_masks"):
        def _broadcast_with_masks(*arrays):
            broadcasted = np.broadcast_arrays(*[np.asarray(arr) for arr in arrays])
            return tuple(broadcasted)

        _mpl_cbook._broadcast_with_masks = _broadcast_with_masks

    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D  # noqa: F401

    fig = plt.figure(figsize=(18, 5))
    ax_true = fig.add_subplot(1, 3, 1, projection="3d")
    ax_obs = fig.add_subplot(1, 3, 2, projection="3d")
    ax_est = fig.add_subplot(1, 3, 3, projection="3d")

    ax_true.plot(sample_X[1:, 0], sample_X[1:, 1], sample_X[1:, 2], label="x (true)", color="tab:blue", linewidth=1.5)
    ax_true.set_title("True state x")
    ax_true.set_xlabel("x1")
    ax_true.set_ylabel("x2")
    ax_true.set_zlabel("x3")
    ax_true.legend(fontsize="small")

    ax_obs.plot(sample_Y[:, 0], sample_Y[:, 1], sample_Y[:, 2], label="y (obs)", color="tab:green", linewidth=1.2)
    ax_obs.set_title("Observation y")
    ax_obs.set_xlabel("y1")
    ax_obs.set_ylabel("y2")
    ax_obs.set_zlabel("y3")
    ax_obs.legend(fontsize="small")

    ax_est.plot(x_hat_np[:, 0], x_hat_np[:, 1], x_hat_np[:, 2], label="$\\hat{x}$ (estimate)", color="tab:orange", linewidth=1.5)
    ax_est.set_title("Estimate $\\hat{x}$")
    ax_est.set_xlabel("x1")
    ax_est.set_ylabel("x2")
    ax_est.set_zlabel("x3")
    ax_est.legend(fontsize="small")

    fig.tight_layout()
    fig.savefig("lorenz_ukf_states.png", dpi=300)

    fig_mse = plt.figure(figsize=(10, 3))
    plt.plot(time_axis, mse_per_step, label="per-step MSE", color="tab:red")
    plt.axhline(0.0, color="black", linewidth=0.8, linestyle=":", label="zero baseline")
    plt.ylabel("MSE")
    plt.xlabel("Time step")
    plt.title("UKF per-step state estimation MSE")
    plt.legend()
    plt.grid(True, linewidth=0.3, alpha=0.7)
    fig_mse.tight_layout()
    fig_mse.savefig("lorenz_ukf_mse.png", dpi=300)

    print(f"Summary stats -> MSE_lin: {mse_lin:.3f}, MSE_dB: {mse_db:.3f}")

    plt.show()
